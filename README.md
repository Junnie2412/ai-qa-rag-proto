# AI-Powered Software Testing Automation App (AI Test Agent)

A prototype platform for **AI-assisted software testing automation**.  
This project provides a reusable and extensible pipeline that allows an AI system to understand **project documents (PDF)** and **web content**, then answer questions, summarize content, and serve as a foundation for further automation such as test-case generation and UI testing.

---

## Project Goals

1) **RAG Knowledge Base from Project Documents**  
   (PDF → Chroma VectorDB → Ollama LLM)

2) **Controlled Web Search & Scraping Pipeline**  
   (Search → Playwright Rendered HTML → Text Extraction → Indexing → Query)

---

## Key Features (Implemented)

### 1. RAG + VectorDB (PDF / Text → Chroma)

- Load PDFs using `PyPDFLoader` (LangChain)
- Chunking via `RecursiveCharacterTextSplitter`
- Embeddings generated by **Ollama embedding models**
  - Default: `embeddinggemma`
- Vector storage using **Chroma VectorDB**
- Querying with **Ollama chat models**
  - Default: `qwen3:1.7b`
- Optional PDF text dump for verification
- Ability to index **plain text files** (used for web content)
- Compatible with Chroma API differences (`filter` vs `where`)

---

### 2. Controlled Web Search & Scraping

#### Web Search
- Google search via `googlesearch-python`
- **Fallback to Viblo search** (Playwright-based) when Google is blocked or returns no results
- Optional domain allowlist via `--allowed-domain`

#### Web Scraping
- Fully rendered HTML using **Playwright**
- Text extraction via **lxml**
- Removes `script`, `style`, `noscript`
- Optional `--content-selector` (e.g. `article`)
- Enforced domain allowlist
- Saved artifacts:
  - `outputs/page.html`
  - `outputs/page.txt`

---

### 3. Separate Vector Databases by Data Source

To avoid data contamination, the project **intentionally separates vector databases**:

```
data/
├─ chroma_docs/   # VectorDB for PDF / internal documents
└─ chroma_web/    # VectorDB for web content (URL-based)
```

- `chroma_docs` → used for PDF RAG
- `chroma_web` → used for web RAG
- Web queries are always filtered by URL metadata

---

### 4. Integrated Pipeline (Single Command)

- **PDF mode**
  - Ingest PDFs → Query
- **URL mode**
  - Search → Scrape → Index → Query (filtered by URL)

---

### 5. Debug & Trace Outputs

Debug artifacts are saved by default:

```
outputs/
├─ last_question.txt
├─ last_answer.txt
├─ last_context.txt
└─ last_hits.json
```

---

### 6. MCP Tool Server

All core capabilities are exposed as MCP tools:

- `atp_web_search`
- `atp_web_scrape`
- `atp_web_index`
- `atp_rag_ingest`
- `atp_rag_query`
- `atp_run`

Supported transports:
- `streamable-http` (recommended)
- `stdio`

---

## Project Structure

```
FinalProject/
├─ docs/                 # Input PDFs
├─ data/
│  ├─ chroma_docs/       # VectorDB for PDFs
│  └─ chroma_web/        # VectorDB for web content
├─ outputs/              # Scraped files + debug outputs
├─ src/atp/
│  ├─ cli.py             # Typer CLI entrypoint (atp)
│  ├─ rag/
│  │  └─ rag_core.py
│  ├─ web/
│  │  ├─ search.py
│  │  ├─ scrape.py
│  │  └─ index.py
│  └─ mcp_server.py
├─ requirements.txt
├─ pyproject.toml
└─ uv.lock
```

---

## Requirements

- Python **3.11+**
- **Ollama** installed and running locally
- **Playwright** (Chromium)

---

## Setup

```bash
pip install -r requirements.txt
playwright install chromium

ollama pull embeddinggemma
ollama pull qwen3:1.7b
```

---

## CLI Usage (Real Examples)

### 1. Query RAG from PDFs

```bash
atp rag-query "What does the document say about the table of contents or main chapters?"   --chroma-dir data/chroma_docs   --embed-model embeddinggemma   --chat-model qwen3:1.7b   --top-k 10
```

---

### 2. Web Search (restricted to Viblo)

```bash
atp web-search "flutter basic first application"   --limit 5   --allowed-domain viblo.asia
```

---

### 3. Web Scrape (extract article content)

```bash
atp web-scrape "https://viblo.asia/p/gioi-thieu-plugins-extensions-tren-chrome-XL6lAgNJKek"   --allowed-domain viblo.asia   --content-selector "article"
```

---

### 4. Index Web Content into Chroma (Web DB)

```bash
rm -rf data/chroma_web
mkdir -p outputs

atp web-index   --url "https://viblo.asia/p/gioi-thieu-plugins-extensions-tren-chrome-XL6lAgNJKek"   --text-path outputs/page.txt   --chroma-dir data/chroma_web   --embed-model embeddinggemma
```

---

### 5. RAG Query via Integrated Pipeline (URL Mode)

```bash
atp run "Summarize the article in 5 bullet points"   --url "https://viblo.asia/p/gioi-thieu-plugins-extensions-tren-chrome-XL6lAgNJKek"   --allowed-domain viblo.asia   --content-selector "article"   --chat-model qwen3:1.7b
```

---

### 6. Direct Query from Web VectorDB

```bash
atp rag-query "Summarize the article in 5 bullet points"   --chroma-dir data/chroma_web   --embed-model embeddinggemma   --chat-model qwen3:1.7b   --top-k 15
```

---

### 7. Ingest PDFs into Chroma (Docs DB)

```bash
rm -rf data/chroma_docs

atp rag-ingest   --docs-dir docs   --chroma-dir data/chroma_docs   --embed-model embeddinggemma
```

---

### 8. Summarize PDFs

```bash
atp rag-query "Summarize the document in 5 bullet points"   --chroma-dir data/chroma_docs   --embed-model embeddinggemma   --chat-model qwen3:1.7b   --top-k 25
```

Or using the integrated pipeline:

```bash
atp run "Summarize the PDF document in 5 bullet points"   --pdf-dir docs   --chat-model qwen3:1.7b
```

---

## Design Notes

- **PDF and Web content are never mixed in the same VectorDB**
- Web retrieval is always filtered by `url`
- RAG prompt enforces context-only answers (guardrail)
- Designed for future extensions:
  - Test-case generation
  - Playwright-based UI automation agents
  - Evidence collection and reporting

---

## License

Prototype / internal research use.
